# 임베딩 모델 벤치마크 결과 보고서 v2

> **Bizi 프로젝트** - 창업/경영 상담 챗봇을 위한 최적 임베딩 모델 선정
>
> OpenAI 모델 vs 오픈소스 모델 비교 포함
>
> 작성일: 2026-01-30

---

## 1. Executive Summary

### 벤치마크 목적
Bizi 프로젝트의 RAG 시스템에 적용할 **최적의 임베딩 모델**을 선정하기 위해 **OpenAI 상용 모델 3개**와 **오픈소스 모델 7개**를 동일한 조건에서 비교 분석하였습니다.

### 핵심 결과

| 항목 | 내용 |
|------|------|
| **테스트 모델 수** | 10개 (OpenAI 3개 + 오픈소스 7개) |
| **최종 선정 모델** | `BAAI/bge-m3` (오픈소스) |
| **HR@5 (최고)** | 42.00% |
| **OpenAI 최고 모델** | text-embedding-3-large (33.33%) |

### 주요 발견

```
🏆 BGE-M3 (오픈소스)가 OpenAI 최신 모델을 압도

   BGE-M3:                 42.00% (1위)
   text-embedding-3-large: 33.33% (6위)

   → 오픈소스가 OpenAI 대비 +26% 성능 우위
   → 비용: 무료 vs $0.13/1M 토큰
```

---

## 2. 벤치마크 개요

### 2.1 테스트 데이터셋

| 항목 | 내용 |
|------|------|
| **총 쿼리 수** | 150개 |
| **도메인** | 3개 (창업/지원, 재무/세무, 인사/노무) |
| **도메인당 쿼리** | 50개 |
| **코퍼스 크기** | 27,499개 청크 |
| **데이터 버전** | v4.0 |

### 2.2 테스트 모델 (10개)

#### OpenAI 상용 모델 (3개)

| 모델 | 차원 | 가격/1M토큰 | 출시 |
|------|------|-------------|------|
| text-embedding-3-large | 3072 | $0.13 | 2024.01 |
| text-embedding-3-small | 1536 | $0.02 | 2024.01 |
| text-embedding-ada-002 | 1536 | $0.10 | 2022.12 |

#### 오픈소스 모델 (7개)

| 모델 | 개발사 | 차원 | 파라미터 |
|------|--------|------|----------|
| BGE-M3 | BAAI | 1024 | 568M |
| multilingual-e5-large | Microsoft | 1024 | 560M |
| multilingual-e5-large-instruct | Microsoft | 1024 | 560M |
| jina-embeddings-v3 | Jina AI | 1024 | 570M |
| multilingual-e5-base | Microsoft | 768 | 278M |
| snowflake-arctic-embed-l-v2.0 | Snowflake | 1024 | 335M |
| snowflake-arctic-embed-m-v1.5 | Snowflake | 768 | 109M |

---

## 3. 평가 지표 (8개)

| 지표 | 설명 | 중요도 |
|------|------|:------:|
| **HR@k (Hit Rate)** | 상위 k개에 정답 포함 비율 | ⭐⭐⭐ |
| **MRR (Mean Reciprocal Rank)** | 첫 정답 순위의 역수 평균 | ⭐⭐⭐ |
| **MAP (Mean Average Precision)** | 평균 정밀도 | ⭐⭐ |
| **Precision@k** | 상위 k개 중 정답 비율 | ⭐⭐ |
| **Recall@k** | 전체 정답 중 검색된 비율 | ⭐⭐ |
| **NDCG@k** | 순위 가중 정규화 점수 | ⭐⭐ |
| **Latency** | 쿼리 임베딩 지연시간 | ⭐ |
| **Similarity Score** | Top-1 유사도 통계 | ⭐ |

---

## 4. 전체 벤치마크 결과

### 4.1 전체 순위 (HR@5 기준)

| 순위 | 모델 | 제공사 | HR@5 | MRR | MAP | 비용 |
|:----:|------|--------|-----:|----:|----:|------|
| 🥇 **1** | **BGE-M3** | BAAI | **42.00%** | **0.3197** | 0.3020 | 무료 |
| 🥈 2 | multilingual-e5-large | Microsoft | 39.33% | 0.3001 | 0.2892 | 무료 |
| 🥉 3 | multilingual-e5-large-instruct | Microsoft | 35.33% | 0.2868 | 0.2753 | 무료 |
| 4 | jina-embeddings-v3 | Jina AI | 34.00% | 0.2776 | 0.2679 | 무료 |
| 5 | multilingual-e5-base | Microsoft | 34.00% | 0.2842 | 0.2750 | 무료 |
| 6 | **text-embedding-3-large** | **OpenAI** | **33.33%** | 0.2945 | - | **$0.13** |
| 7 | **text-embedding-3-small** | **OpenAI** | **25.33%** | 0.1957 | - | **$0.02** |
| 8 | **text-embedding-ada-002** | **OpenAI** | **22.67%** | 0.1924 | - | **$0.10** |
| 9 | snowflake-arctic-embed-l-v2.0 | Snowflake | 17.33% | 0.1119 | 0.1114 | 무료 |
| 10 | snowflake-arctic-embed-m-v1.5 | Snowflake | 0.00% | 0.0000 | 0.0000 | 무료 |

### 4.2 성능 시각화

```
HR@5 성능 비교 (높을수록 좋음)

BGE-M3                    ████████████████████████████████████████████ 42.00%
e5-large                  ███████████████████████████████████████ 39.33%
e5-large-instruct         ███████████████████████████████████ 35.33%
jina-v3                   ██████████████████████████████████ 34.00%
e5-base                   ██████████████████████████████████ 34.00%
text-embedding-3-large    █████████████████████████████████ 33.33%  ← OpenAI 최고
text-embedding-3-small    █████████████████████████ 25.33%
text-embedding-ada-002    ██████████████████████ 22.67%
snowflake-l               █████████████████ 17.33%
snowflake-m               0.00%
                          |----|----|----|----|----|----|
                          0%   10%  20%  30%  40%  50%
```

---

## 5. OpenAI vs 오픈소스 상세 비교

### 5.1 성능 비교

| 비교 항목 | OpenAI (최고) | 오픈소스 (최고) | 차이 |
|-----------|---------------|-----------------|------|
| **모델** | text-embedding-3-large | BGE-M3 | - |
| **HR@5** | 33.33% | **42.00%** | **+8.67%p** |
| **MRR** | 0.2945 | **0.3197** | **+0.0252** |
| **HR@10** | 40.00% | **51.33%** | **+11.33%p** |

### 5.2 도메인별 비교

| 도메인 | OpenAI 3-large | BGE-M3 | 차이 |
|--------|---------------:|-------:|-----:|
| **창업/지원** | 60.00% | **64.00%** | +4.00%p |
| **재무/세무** | 12.00% | **24.00%** | **+12.00%p** |
| **인사/노무** | 28.00% | **38.00%** | **+10.00%p** |
| **평균** | 33.33% | **42.00%** | **+8.67%p** |

### 5.3 비용 비교 (월간 운영 기준)

| 항목 | OpenAI | 오픈소스 |
|------|--------|----------|
| **모델** | text-embedding-3-large | BGE-M3 |
| **임베딩 비용** | ~$50/월 (예상)* | $0 |
| **GPU 비용** | 불필요 | ~$30/월 (클라우드) |
| **총 비용** | **~$50/월** | **~$30/월** |
| **성능** | HR@5 33.33% | **HR@5 42.00%** |

> *월 1,000만 쿼리 기준, 실제 비용은 사용량에 따라 변동

### 5.4 종합 비교

| 평가 항목 | OpenAI | 오픈소스 | 승자 |
|-----------|--------|----------|:----:|
| 검색 정확도 | 33.33% | 42.00% | 🏆 오픈소스 |
| 한국어 성능 | 보통 | 우수 | 🏆 오픈소스 |
| 비용 | 유료 | 무료 | 🏆 오픈소스 |
| 설치 편의성 | 쉬움 | 보통 | 🏆 OpenAI |
| 데이터 프라이버시 | 외부 전송 | 로컬 처리 | 🏆 오픈소스 |
| 확장성 | 무제한 | GPU 의존 | 🏆 OpenAI |

---

## 6. 도메인별 상세 분석

### 6.1 창업/지원 (startup_funding)

| 순위 | 모델 | HR@5 |
|:----:|------|-----:|
| 1 | **BGE-M3** | **64.00%** |
| 2 | text-embedding-3-large | 60.00% |
| 3 | multilingual-e5-large | 58.00% |
| 4 | multilingual-e5-base | 56.00% |
| 5 | multilingual-e5-large-instruct | 54.00% |

**분석**: 창업 절차, 지원사업 공고 등 비교적 명확한 키워드가 많아 전 모델 고성능

### 6.2 재무/세무 (finance_tax)

| 순위 | 모델 | HR@5 |
|:----:|------|-----:|
| 1 | **multilingual-e5-large** | **26.00%** |
| 2 | BGE-M3 | 24.00% |
| 3 | multilingual-e5-large-instruct | 22.00% |
| 4 | jina-embeddings-v3 | 22.00% |
| 5 | text-embedding-3-large | 12.00% |

**분석**:
- 전문 세무 용어, 복잡한 법률 해석으로 전반적 저성능
- **OpenAI가 가장 약한 도메인** (12%)
- 한국어 특화 모델이 우위

### 6.3 인사/노무 (hr_labor)

| 순위 | 모델 | HR@5 |
|:----:|------|-----:|
| 1 | **BGE-M3** | **38.00%** |
| 2 | multilingual-e5-large | 34.00% |
| 3 | multilingual-e5-large-instruct | 30.00% |
| 4 | jina-embeddings-v3 | 30.00% |
| 5 | text-embedding-3-large | 28.00% |

**분석**: 근로기준법, 판례 등 법률 문서 특성상 한국어 이해도가 중요

---

## 7. OpenAI 모델 상세 분석

### 7.1 text-embedding-3-large

```
성능:
  - HR@5: 33.33% (전체 6위)
  - MRR: 0.2945
  - 창업/지원: 60.00% (양호)
  - 재무/세무: 12.00% (매우 낮음)
  - 인사/노무: 28.00% (보통)

장점:
  ✅ 3072 차원 고해상도 임베딩
  ✅ 설치/사용 간편 (API 호출만)
  ✅ 서버 관리 불필요

단점:
  ❌ 한국어 전문 용어 이해 부족
  ❌ 재무/세무 도메인 성능 매우 낮음
  ❌ API 비용 발생 ($0.13/1M 토큰)
  ❌ 데이터 외부 전송 (프라이버시)
```

### 7.2 text-embedding-3-small

```
성능:
  - HR@5: 25.33% (전체 7위)
  - MRR: 0.1957

분석:
  - 3-large 대비 약 8%p 성능 하락
  - 비용은 6배 저렴 ($0.02 vs $0.13)
  - 비용 대비 효율은 양호하나 절대 성능 부족
```

### 7.3 text-embedding-ada-002

```
성능:
  - HR@5: 22.67% (전체 8위)
  - MRR: 0.1924

분석:
  - 2022년 출시된 레거시 모델
  - 최신 3-large 대비 약 10%p 낮음
  - 한국어 성능 특히 약함
  - 업그레이드 권장
```

---

## 8. 왜 오픈소스가 OpenAI보다 좋은가?

### 8.1 한국어 특화 학습

| 요인 | OpenAI | 오픈소스 (BGE-M3, E5) |
|------|--------|----------------------|
| 학습 데이터 | 영어 중심 | 다국어 균형 |
| 한국어 비중 | 낮음 | 높음 |
| 한국어 법률 용어 | 미학습 | 일부 학습 |
| 문화적 맥락 | 부족 | 반영됨 |

### 8.2 모델 아키텍처

```
BGE-M3의 강점:
  - Dense + Sparse + ColBERT 하이브리드 구조
  - 키워드 매칭과 의미 검색 동시 지원
  - 8192 토큰 긴 문맥 처리

OpenAI의 한계:
  - Dense 임베딩만 지원
  - 블랙박스 모델 (구조 비공개)
  - 한국어 최적화 부족
```

### 8.3 도메인 특성

```
한국 법률/행정 문서 특성:
  - 한자어 혼용 (예: 근로기준법, 부가가치세)
  - 복잡한 문장 구조
  - 전문 용어 다수

→ 한국어 특화 학습된 오픈소스 모델이 유리
→ OpenAI는 일반적인 영어 텍스트에 최적화
```

---

## 9. 비용 효율성 분석

### 9.1 예상 월간 비용 (1,000만 쿼리 기준)

| 항목 | OpenAI 3-large | BGE-M3 (클라우드) |
|------|---------------:|------------------:|
| 임베딩 API | $130 | $0 |
| GPU 서버 | $0 | $50 |
| **총 비용** | **$130** | **$50** |
| **HR@5** | 33.33% | 42.00% |
| **비용당 성능** | 0.26%/$ | **0.84%/$** |

### 9.2 성능당 비용 비교

```
1% HR@5 향상에 필요한 비용:

OpenAI 3-large:  $130 ÷ 33.33% = $3.90 per 1%
BGE-M3:          $50 ÷ 42.00% = $1.19 per 1%

→ BGE-M3가 3.3배 비용 효율적
```

---

## 10. 최종 권장사항

### 10.1 모델 선정 결론

| 우선순위 | 모델 | 용도 | 비용 |
|:--------:|------|------|------|
| **1순위** | **BGE-M3** | 메인 검색 모델 | 무료 |
| 2순위 | multilingual-e5-large | 백업/경량 환경 | 무료 |
| 3순위 | text-embedding-3-large | OpenAI 필수 시 | $0.13/1M |

### 10.2 OpenAI 사용이 적합한 경우

```
✅ GPU 서버 구축이 어려운 경우
✅ 빠른 프로토타이핑이 필요한 경우
✅ 영어 위주 서비스인 경우
✅ 소규모 트래픽 (비용 부담 적음)
```

### 10.3 오픈소스(BGE-M3) 사용이 적합한 경우

```
✅ 한국어 전문 문서 검색 (법률, 행정, 세무)
✅ 비용 최적화가 중요한 경우
✅ 데이터 프라이버시가 중요한 경우
✅ 대규모 트래픽 예상
✅ 검색 품질이 최우선인 경우
```

### 10.4 Bizi 프로젝트 적용 방안

```python
# 권장 설정: BGE-M3
from sentence_transformers import SentenceTransformer

model = SentenceTransformer(
    "BAAI/bge-m3",
    trust_remote_code=True,
    device="cuda"
)

# 임베딩 생성
embeddings = model.encode(
    texts,
    batch_size=8,
    normalize_embeddings=True
)
```

---

## 11. 부록

### 11.1 테스트 환경

| 항목 | OpenAI | 오픈소스 |
|------|--------|----------|
| 실행 환경 | API 호출 (로컬) | RunPod GPU |
| GPU | 불필요 | RTX 3090/4090 24GB |
| Python | 3.11 | 3.11 |
| 소요 시간 | ~19분 | ~15분/모델 |

### 11.2 OpenAI API 비용 상세

| 모델 | 테스트 비용 | 토큰 사용량 |
|------|------------|-------------|
| text-embedding-3-large | ~$2.60 | ~20M 토큰 |
| text-embedding-3-small | ~$0.40 | ~20M 토큰 |
| text-embedding-ada-002 | ~$2.00 | ~20M 토큰 |
| **총합** | **~$5.00** | ~60M 토큰 |

### 11.3 실패한 모델

| 모델 | 실패 원인 |
|------|----------|
| bge-multilingual-gemma2 | GPU 메모리 부족 (9B 파라미터) |
| gte-Qwen2-1.5B-instruct | 시간 초과 (1.5B 파라미터) |

---

## 12. 결론

### 최종 선정: `BAAI/bge-m3` (오픈소스)

| 평가 항목 | 결과 |
|-----------|------|
| **검색 정확도** | HR@5 42.00% (1위) |
| **OpenAI 대비** | +26% 성능 향상 |
| **비용** | 무료 (API 비용 없음) |
| **한국어 성능** | 우수 |
| **데이터 보안** | 로컬 처리 가능 |

### 핵심 메시지

```
"OpenAI가 항상 최고는 아니다"

- 한국어 전문 도메인에서는 오픈소스가 우수
- BGE-M3는 OpenAI 3-large보다 26% 더 정확
- 비용도 더 저렴하고 프라이버시도 보장
- Bizi 프로젝트에 BGE-M3 채택 권장
```

---

*본 보고서는 2026년 1월 30일 기준으로 작성되었습니다.*
*테스트 데이터: 150개 쿼리, 27,499개 문서 청크*
