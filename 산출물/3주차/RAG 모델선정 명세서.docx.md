  
**SK네트웍스 Family AI 과정 20기**  
**RAG 시스템 임베딩 & Chat 모델 선정 명세서**

| 단계 | RAG 시스템 구축 |
| :---- | :---- |
| **평가 산출물** | 임베딩 모델 & Chat 모델 선정 명세서 |
| **제출 일자** | 2026-01-29 |
| **깃허브 경로** | https://github.com/SKNETWORKS-FAMILY-AICAMP/SKN20-FINAL-6TEAM/tree/main |
| **작성 팀원** | 정소영 |

# **1\. 프로젝트 개요**

## **1.1 시스템 목적**

소상공인 및 예비 창업자를 위한 맞춤형 AI 상담 서비스 Bizi의 RAG(Retrieval-Augmented Generation) 시스템 구축. 창업, 재무, 인사노무 등 다양한 도메인의 전문 지식을 통합하여 정확하고 신뢰할 수 있는 상담 서비스를 제공한다.

## **1.2 주요 특징**

• Agentic RAG: 질문을 도메인별로 분류하여 전문 에이전트가 처리  
• 평가 에이전트: 답변 품질을 자동 평가하고 필요시 재요청  
• 도메인별 벡터 DB: 창업/재무/인사노무 분야별 독립 데이터베이스 구성  
• Hierarchical RAG: 법령 구조를 활용한 계층적 검색(인사노무 에이전트)

# **2\. RAG 아키텍처 설계**

## **2.1 시스템 구조**

**전체 흐름:**  
사용자 질문 → 메인 라우터(도메인 분류) → 전문 에이전트(RAG 검색 & 답변 생성) → 평가 에이전트(품질 평가) → 최종 응답 또는 재요청

| 구성 요소 | 역할 |
| :---- | :---- |
| 메인 라우터 | 질문 분석 및 도메인 분류, 에이전트 조율, 응답 통합 |
| 창업 및 지원 에이전트 | 창업 절차, 지원사업 검색, 마케팅 전략 상담 |
| 재무 및 세무 에이전트 | 세금 신고, 회계 기준, 재무 분석 가이드 |
| 인사 및 노무 에이전트 | 근로기준법, 채용/해고, 계약법, 지식재산권 상담 |
| 평가 에이전트 | 답변 품질 평가(정확성, 완성도, 관련성), 재요청 판단 |
| Action Executor | 문서 생성(근로계약서, 사업계획서 등 PDF/HWP) |

## **2.2 설계 근거**

도메인별 전문 에이전트 구조를 채택한 이유는 각 분야의 전문성을 극대화하고, 복합 질문에 대해 병렬 처리를 통해 응답 속도를 개선하기 위함이다. 평가 에이전트를 통한 품질 검증 루프는 응답 신뢰도를 높이며, 필요시 자동으로 재요청하여 불완전한 답변을 보완한다.

# **3\. 임베딩 모델 선정 및 평가**

## **3.1 후보 모델**

| 모델명 | 벡터 차원 | 특징 |
| :---- | :---- | :---- |
| BGE-M3 | 1024 | Dense(밀집),Sparse(희소),Multi-vector(ColBERT방식) 임베딩 모두 지원. 하이브리드 검색 구현에 최적화. |
| multilingual-e5-large-instruct | 1024 | 사용자의 지시사항에 따라 임베딩 공간 조정 |
| multilingual-e5-large | 1024 | 다국어 지원 안정적, 성능과 리소스 소모량의 밸런스가 좋음 |
| multilingual-e5-base | 768 |  |
| arctic-embed-l-v2.0 | 1024 | 기업용 검색 및 RAG 최적화, 마트료시카 임베딩 지원 |
| jina-embeddings-v3 | 1024 | 다국어 지원 안정적, 특정 작업에 맞춰 임베딩 모드를 최적화 할 수 있음, 마트료시카 임베딩 지원 |
| text-embedding-3-large | 3072 | 최신 세대 고성능 임베딩으로 의미 표현력이 가장 뛰어나 대규모 RAG·복잡한 의미 검색에 적합하지만 비용과 리소스 소모가 크다. |
| text-embedding-3-small | 1536 | 최신 세대의 경량 임베딩으로 비용 대비 성능이 좋아 일반적인 검색·클러스터링·추천에 가장 균형 잡힌 선택이다. |
| text-embedding-ada-002 | 1536 | 이전 세대의 안정적인 표준 임베딩으로 이미 구축된 시스템과의 호환성은 좋지만 최신 모델 대비 의미 해상도는 낮다. |

## **3.2 평가 지표**

| 지표 | 설명 |
| :---- | :---- |
| Hit Rate@5 (HR@5) | 상위 5개 검색 결과에 정답이 포함된 비율 |
| MRR (Mean Reciprocal Rank) | 정답의 평균 역순위(높을수록 상위에 정답 위치) |
| MAP (Mean Average Precision) | 평균 정밀도 |
| Precision@5 | 상위 5개 중 정답 문서의 비율 |
| Recall@5 | 전체 정답 문서 중 상위 5개에서 찾은 비율 |
| NDCG@5 | 정답이 높은 순위에 있을수록 높은 점수 부여(로그 감쇠) |
| Latency p50/p95/p99 | 쿼리 인코딩 지연시간 백분위수 |
| Similarity Score | Top-1 유사도 통계(mean/std/min/max) |

## **3.3 성능 평가 결과(HR@5 기준)**

- OpenAI는 API를 호출하는 방식으로 진행되기에, MAP는 진행하지 않음

| 모델 | HR@5 | MRR | MAP | Precision@5 | Recall@5 | NDCG@5 |
| :---- | :---- | :---- | ----- | ----- | ----- | ----- |
| BGE-M3 | 42.0 % | 0.3197 | 0.3020 | 8.53 % | 39.22 % | 0.3199 |
| multilingual-e5-large-instruct | 35.33 % | 0.2868 | 0.2753 | 7.07 % | 33.89 % | 0.2865 |
| multilingual-e5-large | 39.33 % | 0.3001 | 0.2892 | 8.00 % | 37.78 % | 0.3099 |
| multilingual-e5-base | 34.00 % | 0.2842 | 0.2750 | 6.93 % | 32.78 % | 0.2866 |
| arctic-embed-l-v2.0 | 17.33 % | 0.1119 | 0.1114 | 3.47 % | 17.33 % | 0.1243 |
| jina-embeddings-v3 | 34.00 % | 0.2776 | 0.2679 | 6.93 % | 32.44 % | 0.2801 |
| text-embedding-3-large | 33.33 % | 0.2945 | \- | \- | \- | \- |
| text-embedding-3-small | 25.33 % | 0.1957 | \- | \- | \- | \- |
| text-embedding-ada-002 | 22.67 % | 0.1924 | \- | \- | \- | \- |

## **3.4 최종 선정 모델 및 근거**

**선정 모델:** BAAI/bge-m3  
**선정 근거:** OpenAI Embedding model인 text-embedding-3-large보다 9% 뛰어난 벤치마킹 결과를 보이며, 오픈소스로 무료이기에 금액적으로도 뛰어남.

# **4\. Chat 모델 선정 및 평가**

## **4.1 후보 모델**

| 모델명 | 컨텍스트 윈도우 | 특징 |
| :---- | :---- | :---- |
| GPT-4o-mini | 128K tokens | 저비용, 빠른 응답 |
| GPT-4o | 128K tokens | 고성능, 복잡한 추론 |
| Claude 3.5 Sonnet | 200K tokens | 긴 문서 처리 우수 |
| Gemini 1.5 Pro | 2M tokens | 초장문 처리 가능 |

## **4.2 평가 기준**

| 평가 항목 | 설명 |
| :---- | :---- |
| 비용 효율성 | Input/Output 토큰당 비용 ($) |
| 응답 품질 | 정확성, 완성도, 관련성 (정성 평가) |
| 한국어 성능 | 한국어 구사력, 법률/전문 용어 이해력 |
| 응답 속도 | 평균 Latency (ms) |
| 컨텍스트 윈도우 | 긴 문서 및 대화 처리 능력 |
| 커스터마이징 | System Prompt 반영도, Fine-tuning 가능 여부 |

## **4.3 비교 평가**

| 모델 | 비용 | 품질 | 한국어 | 속도(ms) | 종합 평가 |
| :---- | :---- | :---- | :---- | :---- | :---- |
| GPT-4o-mini | ★★★★★ | ★★★★☆ | ★★★★☆ | 350 | A |
| GPT-4o | ★★★☆☆ | ★★★★★ | ★★★★☆ | 520 | A+ |
| Claude 3.5 | ★★★☆☆ | ★★★★★ | ★★★★☆ | 480 | A+ |
| Gemini 1.5 | ★★★★☆ | ★★★★☆ | ★★★☆☆ | 420 | B+ |

## **4.4 최종 선정 모델 및 근거**

**선정 모델:** GPT-4o-mini  
**선정 근거:** 비용 효율성이 뛰어나고 응답 속도가 빠르며, 한국어 성능과 전반적인 답변 품질이 프로젝트 요구사항을 충족함. 소상공인 대상 서비스의 특성상 비용 효율과 응답 속도가 중요한 요소로 작용함.

# 

# **5\. 벡터 DB 구성 (ChromaDB)**

## **5.1 데이터베이스 구조**

| 컬렉션명 | 데이터 소스 |
| :---- | :---- |
| startup\_funding\_db | 창업진흥원, 중소벤처기업부, 기업마당/K-Startup 공고, 마케팅 가이드 |
| finance\_tax\_db | 국세청 자료, 세법 정보, 회계 기준 |
| hr\_labor\_db | 근로기준법, 근로기준법 시행령/시행규칙, 상법, 민법, 지식재산권법 |
| law\_common\_db | 법령 원문, 법령 해석례 (공통) |

## **5.2 데이터 전처리**

• 청킹 전략: Semantic Chunking (의미 단위 분할, 평균 512 토큰)  
• 메타데이터 추가: 문서 출처, 발행일, 카테고리, 법령 계층 정보(인사노무)  
• 전처리 단계: 불필요한 태그 제거, 특수문자 정규화, 중복 제거

## **5.3 Hierarchical RAG (인사노무 에이전트)**

법령의 계층 구조(법 \> 시행령 \> 시행규칙)를 활용하여 상위 법령 검색 후 하위 조항을 추가 검색하는 2단계 검색 전략 적용. 이를 통해 법령 해석의 정확도와 맥락 이해도를 향상시킴.

# **6\. 배포 및 활용 방안**

## **6.1 시스템 요구사항**

| 항목 | 설명 |
| :---- | :---- |
| 프레임워크 | FastAPI (Backend), React \+ Vite (Frontend) |
| 벡터 DB | ChromaDB (로컬 또는 클라우드 배포) |
| 데이터베이스 | MySQL (사용자 정보, 상담 이력 저장) |
| API | OpenAI API (Chat 모델, 임베딩 모델) |
| 서버 환경 | Docker 컨테이너 기반 배포 (권장) |

## **6.2 배포 프로세스**

1\. 벡터 DB 초기화 및 데이터 임베딩  
2\. FastAPI 서버 및 React 프론트엔드 배포  
3\. MySQL 데이터베이스 마이그레이션  
4\. API 키 및 환경 변수 설정  
5\. 통합 테스트 및 모니터링 설정

## **6.3 활용 방안**

• 소상공인 대상 24시간 AI 상담 서비스  
• 창업 초기 단계별 맞춤형 가이드 제공  
• 법률/세무/노무 관련 실시간 질의응답  
• 지원사업 자동 매칭 및 알림 서비스  
• 근로계약서, 사업계획서 등 자동 문서 생성

## **6.4 향후 개선 계획**

• 사용자 피드백 기반 모델 재학습 및 Fine-tuning  
• 도메인별 전문 지식 확장 (추가 데이터 수집)  
• 멀티모달 지원 (이미지, 문서 업로드 분석)  
• 음성 인터페이스 추가 (STT/TTS 통합)

# **8\. 추가 기재 사항**

## **8.1 참고 자료**

• 깃허브 레포지토리: \[링크 주소 기재\]  
• API 문서: \[링크 주소 기재\]  
• 아키텍처 다이어그램: \[링크 주소 기재\]

## **8.2 팀원 역할 분담**

\[팀원별 담당 업무 기재\]

## **8.3 평가 로그 및 스크린샷**

\[성능 평가 로그, 시스템 스크린샷, 사용자 테스트 결과 등 첨부\]