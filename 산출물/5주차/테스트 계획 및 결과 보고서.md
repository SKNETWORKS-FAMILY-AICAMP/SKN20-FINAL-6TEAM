**SK네트웍스 Family AI 과정 20기**  
**테스트 계획 및 결과 보고서**

| 항목 | 내용 |
| :---- | :---- |
| 산출물 단계 | 모델링 및 평가 |
| 평가 산출물 | 테스트 계획 및 결과 보고서 |
| 제출 일자 | 2026-02-12 |
| 작성 팀원 | 정소영 |

# 프로젝트 개요

본 문서는 BIZI RAG 시스템의 테스트 계획/결과를 근거 중심으로 재정리한 개정본입니다. [근거: 프로젝트 개요, rag/agents/router.py:363]
BIZI 파이프라인은 질문 분류-질문 분해-검색/생성-평가 순서로 동작하며, 평가 단계는 LLM 운영 판정과 RAGAS 모니터링을 분리해 구성되어 있습니다. [근거: rag/agents/router.py:363, rag/agents/router.py:369, rag/agents/router.py:388]

# 1. 테스트 목적

1) 질문 분해 로직 정확성 검증: 단일 도메인 스킵, 복합 도메인 분해, JSON 실패 폴백, 이력 기반 분해를 확인합니다. [근거: rag/tests/test_question_decomposer.py:53, rag/tests/test_question_decomposer.py:85, rag/tests/test_question_decomposer.py:149, rag/tests/test_question_decomposer.py:230]

2) 도메인 라우터 동작 검증: 관련/비관련 분기(continue/reject), 신뢰도 엣지 케이스, 지연 로딩을 확인합니다. [근거: rag/tests/test_router.py:167, rag/tests/test_router.py:221, rag/tests/test_router.py:520, rag/tests/test_router.py:433]

3) 응답 품질 평가 모듈 검증: 운영 판정은 LLM 평가를 사용하고, RAGAS는 선택적 정량 모니터링으로 동작하는지 확인합니다. [근거: rag/agents/router.py:363, rag/agents/router.py:370, rag/agents/router.py:388, rag/utils/config/settings.py:75, rag/utils/config/settings.py:78]

4) 비기능 요구사항 검증: 폴백 안정성, 캐시 동작, 비동기 함수 경로, 비활성화 시 graceful 처리 여부를 확인합니다. [근거: rag/tests/test_question_decomposer.py:149, rag/tests/test_question_decomposer.py:282, rag/tests/test_question_decomposer.py:339, rag/tests/test_ragas_evaluator.py:85]

# 2. 테스트 환경 및 실행 전제

| 구분 | 값 | 근거 |
| :---- | :---- | :---- |
| 테스트 프레임워크 | pytest, pytest-asyncio | - |
| 목업/패치 | unittest.mock (MagicMock, AsyncMock, patch) | - |
| 운영 LLM 평가 | enable_llm_evaluation=True (기본) | rag/utils/config/settings.py:75 |
| 운영 RAGAS 평가 | enable_ragas_evaluation=False (기본) | rag/utils/config/settings.py:78 |
| LLM 평가 임계값 | evaluation_threshold=70 | rag/utils/config/settings.py:226, rag/tests/test_evaluator.py:125 |
| 기본 OpenAI 모델 | gpt-4o-mini | rag/utils/config/settings.py:129 |

# 3. 테스트 대상 모듈

## 3.1 Question Decomposer (`rag/tests/test_question_decomposer.py`)

테스트 클래스 7개, 테스트 함수 19개를 기준으로 검증 범위를 집계했습니다. [근거: rag/tests/test_question_decomposer.py:52, rag/tests/test_question_decomposer.py:82, rag/tests/test_question_decomposer.py:146, rag/tests/test_question_decomposer.py:227, rag/tests/test_question_decomposer.py:279, rag/tests/test_question_decomposer.py:339, rag/tests/test_question_decomposer.py:379]

| 테스트 클래스 | 검증 내용 | 근거 |
| :---- | :---- | :---- |
| TestSingleDomainSkip | 단일 도메인에서는 원문 반환(LLM 분해 스킵) | rag/tests/test_question_decomposer.py:53 |
| TestMultiDomainDecompose | 2개/3개 도메인 복합 질문 분해 | rag/tests/test_question_decomposer.py:85, rag/tests/test_question_decomposer.py:111 |
| TestFallback | JSON 실패/빈 결과/잘못된 도메인 폴백 | rag/tests/test_question_decomposer.py:149, rag/tests/test_question_decomposer.py:170, rag/tests/test_question_decomposer.py:193 |
| TestHistory | history 섹션 반영, 최근 N턴(max_turns) 제한 | rag/tests/test_question_decomposer.py:230, rag/tests/test_question_decomposer.py:257 |
| TestCaching | 캐시 히트/미스, history 포함 키 생성 | rag/tests/test_question_decomposer.py:282, rag/tests/test_question_decomposer.py:301, rag/tests/test_question_decomposer.py:319 |
| TestAsync | 비동기 분해 경로(`ainvoke`) 검증 | rag/tests/test_question_decomposer.py:339 |
| TestUtilityFunctions | role 필터, 키 결정성/도메인 순서 독립성 | rag/tests/test_question_decomposer.py:385, rag/tests/test_question_decomposer.py:396, rag/tests/test_question_decomposer.py:401 |

## 3.2 Main Router (`rag/tests/test_router.py`)

테스트 클래스 6개, 테스트 함수 20개를 기준으로 검증 범위를 집계했습니다. [근거: rag/tests/test_router.py:113, rag/tests/test_router.py:150, rag/tests/test_router.py:416]

| 테스트 클래스 | 검증 내용 | 근거 |
| :---- | :---- | :---- |
| TestMainRouterInit | 4개 도메인 에이전트/평가기 초기화 확인 | rag/tests/test_router.py:119, rag/tests/test_router.py:138 |
| TestShouldContinueAfterClassify | 분류 결과 없음/관련/비관련의 continue/reject 분기 | rag/tests/test_router.py:167, rag/tests/test_router.py:191, rag/tests/test_router.py:221 |
| TestClassifyNode | 분류 결과 state 반영, 관련성 분기 처리 | rag/tests/test_router.py:304, rag/tests/test_router.py:340, rag/tests/test_router.py:342 |
| TestLazyLoadingProperties | classifier/decomposer/ragas_evaluator 지연 로딩 | rag/tests/test_router.py:433, rag/tests/test_router.py:450, rag/tests/test_router.py:464, rag/tests/test_router.py:471 |
| TestMainRouterEdgeCases | 낮은 신뢰도 관련질문 continue, 높은 신뢰도 비관련질문 reject | rag/tests/test_router.py:520, rag/tests/test_router.py:553 |
| Async Graph 검증 | `async_graph` 생성 확인 | rag/tests/test_router.py:141, rag/tests/test_router.py:147 |

## 3.3 RAGAS Evaluator (`rag/tests/test_ragas_evaluator.py`)

테스트 클래스 2개, 테스트 함수 17개를 기준으로 검증 범위를 집계했습니다. [근거: rag/tests/test_ragas_evaluator.py:9, rag/tests/test_ragas_evaluator.py:82]

| 검증 항목 | 요약 | 근거 |
| :---- | :---- | :---- |
| 메트릭 데이터 구조 | available 판단, to_dict 반올림, 에러 포함 | rag/tests/test_ragas_evaluator.py:35, rag/tests/test_ragas_evaluator.py:69, rag/tests/test_ragas_evaluator.py:63 |
| 비활성/미설치 처리 | `_RAGAS_AVAILABLE=False` 시 비활성 및 에러 반환 | rag/tests/test_ragas_evaluator.py:85, rag/tests/test_ragas_evaluator.py:91 |
| 설정 비활성 처리 | `enable_ragas_evaluation=False` 시 비활성 | rag/tests/test_ragas_evaluator.py:116 |
| 안전 형변환 | `_safe_float`가 None/NaN/invalid를 안전 처리 | rag/tests/test_ragas_evaluator.py:133, rag/tests/test_ragas_evaluator.py:137, rag/tests/test_ragas_evaluator.py:141 |

RAGAS 모듈은 선택적 의존성으로 설계되어, 미설치 또는 설정 비활성 상태에서 graceful하게 실패를 격리합니다. [근거: rag/evaluation/ragas_evaluator.py:18, rag/evaluation/ragas_evaluator.py:277, rag/evaluation/ragas_evaluator.py:303]

## 3.4 LLM Evaluator (`rag/tests/test_evaluator.py`)

테스트 클래스 2개, 테스트 함수 7개를 기준으로 검증 범위를 집계했습니다. [근거: rag/tests/test_evaluator.py:9, rag/tests/test_evaluator.py:96]

| 검증 항목 | 요약 | 근거 |
| :---- | :---- | :---- |
| JSON 파싱 성공 | 코드블록 JSON/일반 JSON 파싱 성공 | rag/tests/test_evaluator.py:19, rag/tests/test_evaluator.py:41 |
| JSON 파싱 실패 처리 | invalid JSON 시 기본값(재시도 유도 점수) 처리 | rag/tests/test_evaluator.py:62, rag/agents/evaluator.py:101 |
| 필수 필드 검증 | `scores` 누락 시 실패 처리 | rag/tests/test_evaluator.py:72, rag/agents/evaluator.py:84 |
| 평가 기준 5개 검증 | 프롬프트에 5개 기준 키 존재 확인 | rag/tests/test_evaluator.py:80, rag/tests/test_evaluator.py:83 |
| 임계값 70 검증 | 70점 통과 / 69점 실패 | rag/tests/test_evaluator.py:118, rag/tests/test_evaluator.py:125 |

LLM 평가 결과(`total_score`, `passed`)는 라우터의 재시도/통과 제어에 직접 사용됩니다. [근거: rag/agents/router.py:379, rag/agents/router.py:412, rag/agents/evaluator.py:173]

## 3.5 평가 방식 선택 근거 (RAGAS vs LLM)

### 3.5.1 선택 기준(장단점/적용 조건)

| 선택 기준 | RAGAS (장단점/적용 조건) | LLM 평가 (장단점/적용 조건) | 근거 |
| :---- | :---- | :---- | :---- |
| 운영 제어(재시도 트리거) | 장점: faithfulness 등 정량 지표 제공. 단점: 현재 라우터 재시도 트리거로 직접 사용되지 않음. 적용: 모니터링/관측 중심. | 장점: total_score/pass가 즉시 운영 제어에 사용됨. 단점: 모델 판단 편차 가능. 적용: 실시간 합/불 판정 필요 시. | rag/agents/router.py:379, rag/agents/router.py:388 |
| 출력 구조화 가능성(JSON 고정) | 점수 객체 반환 구조는 안정적이나 라이브러리/환경 의존성 존재. | 프롬프트에서 JSON 스키마 강제(`scores`, `total_score`, `passed`, `feedback`) + 파싱 검증/기본값 제공. | rag/utils/prompts.py:395, rag/agents/evaluator.py:84, rag/agents/evaluator.py:101 |
| 비활성/미설치 graceful 처리 | `_RAGAS_AVAILABLE` 및 설정 플래그로 비활성화 가능, 에러 메트릭 반환. | JSON 파싱 실패 시 기본 평가값으로 폴백하고 재시도 경로 유지. | rag/evaluation/ragas_evaluator.py:18, rag/evaluation/ragas_evaluator.py:277, rag/evaluation/ragas_evaluator.py:303, rag/agents/evaluator.py:101 |
| 품질 모니터링 지표 제공성 | faithfulness/answer_relevancy/context_precision(/recall) 지표 제공. | 검색품질/정확성/완성도/관련성/출처의 5축 점수 제공. | rag/evaluation/ragas_evaluator.py:5, rag/utils/prompts.py:360 |

### 3.5.2 우리 선택

- 운영 판정/재시도 제어: LLM 평가 사용. [근거: rag/agents/router.py:363, rag/agents/router.py:370, rag/agents/router.py:379]
- 정량 모니터링/관측: RAGAS 선택적 사용. [근거: rag/agents/router.py:388, rag/agents/router.py:404]
- 기본 플래그: `enable_llm_evaluation=True`, `enable_ragas_evaluation=False`. [근거: rag/utils/config/settings.py:75, rag/utils/config/settings.py:78]

### 3.5.3 `test_evaluator.py` 프롬프트 근거

`test_evaluator.py`는 `EVALUATOR_PROMPT`의 핵심 계약(기준/출력/임계값)을 검증합니다. [근거: rag/tests/test_evaluator.py:80, rag/tests/test_evaluator.py:83]

- 5개 항목 각 20점(총 100점): retrieval_quality, accuracy, completeness, relevance, citation. [근거: rag/utils/prompts.py:360, rag/utils/prompts.py:399]
- JSON 스키마 키 강제: `scores`, `total_score`, `passed`, `feedback`. [근거: rag/utils/prompts.py:395, rag/utils/prompts.py:405, rag/utils/prompts.py:406, rag/utils/prompts.py:407]
- PASS/FAIL 기준 70점: 총점 70 이상 PASS, 미만 FAIL. [근거: rag/utils/prompts.py:413, rag/tests/test_evaluator.py:125]

# 4. 테스트 케이스 통계 및 분류

현재 문서에서 근거 추적 대상으로 집계한 핵심 테스트는 63개입니다. [근거: rag/tests/test_question_decomposer.py(test_* 19), rag/tests/test_router.py(test_* 20), rag/tests/test_ragas_evaluator.py(test_* 17), rag/tests/test_evaluator.py(test_* 7)]

| 모듈 | 테스트 함수 수 | 근거 |
| :---- | :---: | :---- |
| Question Decomposer | 19 | rag/tests/test_question_decomposer.py (`test_*` 집계) |
| Main Router | 20 | rag/tests/test_router.py (`test_*` 집계) |
| RAGAS Evaluator | 17 | rag/tests/test_ragas_evaluator.py (`test_*` 집계) |
| LLM Evaluator | 7 | rag/tests/test_evaluator.py (`test_*` 집계) |
| 합계 | 63 | 상기 4개 파일 집계 합 |

## 4.1 요구사항-테스트 매핑 (Traceability Matrix)

| 요구사항 ID | 요구사항(문서 기준) | 평가 기준(Threshold/판정 방식) | 검증 테스트 | 근거(파일:라인) | 결과 근거(문서 위치) | 비고 |
| :---- | :---- | :---- | :---- | :---- | :---- | :---- |
| FR-01 | 복합 질문을 도메인별로 분해해야 한다 | 정량 임계값 없음. 분해 결과가 감지 도메인과 정합하며, 실패 시 원문 폴백이면 통과 | `TestMultiDomainDecompose`, `TestFallback` | rag/tests/test_question_decomposer.py:85, rag/tests/test_question_decomposer.py:111, rag/tests/test_question_decomposer.py:149 | §3.1 | JSON 실패 시 폴백 포함 |
| FR-02 | 관련 질문은 continue, 비관련 질문은 reject 해야 한다 | 판정 방식: `relevant=True -> continue`, `relevant=False -> reject` (신뢰도 엣지 케이스 포함) | `TestShouldContinueAfterClassify`, `TestMainRouterEdgeCases` | rag/tests/test_router.py:167, rag/tests/test_router.py:221, rag/tests/test_router.py:520, rag/tests/test_router.py:553 | §3.2 | confidence 엣지 케이스 포함 |
| FR-03 | 평가 결과는 구조화(JSON)되고 임계값 기반 판정이 가능해야 한다 | Threshold: `total_score >= 70` PASS, `< 70` FAIL. 판정 방식: JSON 필수 필드(`scores`, `total_score`, `passed`, `feedback`) 검증 | `test_parse_evaluation_valid_json`, `test_parse_evaluation_invalid_json`, `test_evaluation_result_threshold` | rag/tests/test_evaluator.py:19, rag/tests/test_evaluator.py:62, rag/tests/test_evaluator.py:118 | §3.4, §3.5.3 | 70점 기준 판정 |
| FR-04 | RAGAS는 선택적으로 활성화되고 비활성/미설치 시 안정적으로 동작해야 한다 | 판정 방식: `_RAGAS_AVAILABLE=False` 또는 `enable_ragas_evaluation=False`면 비활성/에러 반환 | `test_evaluator_disabled_when_ragas_not_available`, `test_evaluator_disabled_when_config_disabled` | rag/tests/test_ragas_evaluator.py:85, rag/tests/test_ragas_evaluator.py:116 | §3.3, §3.5.1 | graceful handling |
| NFR-01 | 오류 상황에서 서비스가 중단 없이 폴백해야 한다 | 판정 방식: JSON/응답 오류 시 기본값 또는 원문 폴백 반환, 파이프라인 중단 없음 | invalid JSON/empty 결과 폴백, evaluator 기본값 반환 | rag/tests/test_question_decomposer.py:149, rag/tests/test_question_decomposer.py:170, rag/agents/evaluator.py:101 | §3.1, §3.4 | 복원력(resilience) |
| NFR-02 | 성능 최적화를 위한 캐시/지연로딩이 동작해야 한다 | 판정 방식: cache hit/miss와 lazy loading 상태 전이가 기대대로 동작하면 통과 | 캐시 히트/미스, lazy loading | rag/tests/test_question_decomposer.py:282, rag/tests/test_question_decomposer.py:301, rag/tests/test_router.py:433, rag/tests/test_router.py:464 | §3.1, §3.2 | 비기능 검증 |

# 5. 테스트 실행 결과
| 항목 | 인용 값 |
| :---- | :---- |
| 전체 테스트 | 75 |
| 통과 | 69 (92.0%) |
| 실패 | 0 (0.0%) |
| ERROR | 6 |
| 주요 ERROR 원인 | `'MainRouter' object has no attribute 'rag_chain'` |
| 평균 점수 | 91.1/100 |
| 총 비용 | $0.1498 |

ERROR 6건은 환경/속성 초기화 누락(rag_chain attribute) 이슈로, 기능 결함이 아닌 테스트 환경 설정 문제로 분류됨.

# 6. 모델링 평가 결과 전반
| 검증 항목 | 평균 | 최저 | 최고 |
| :---- | :---: | :---: | :---: |
| 검색 품질 | 17.8 | 15 | 20 |
| 정확성 | 18.9 | 18 | 20 |
| 완성도 | 18.2 | 17 | 20 |
| 관련성 | 19.4 | 19 | 20 |

## 6.1 LLM 평가의 주관성·재현성 완화책

### 리스크
- 주관성: LLM이 자연어 기준을 해석해 점수를 산출하므로 동일 의미 답변에서도 판정 편차 가능성이 있습니다. [근거: rag/utils/prompts.py:357, rag/agents/evaluator.py:152]
- 비결정성: 평가가 LLM 호출 기반이며 모델/설정값에 의존하므로 운영 환경 변화 시 점수 변동 가능성이 있습니다. [근거: rag/agents/evaluator.py:55, rag/utils/config/settings.py:129, rag/utils/config/settings.py:130]
- 파싱 불안정: 자유형 텍스트 출력 시 JSON 파싱 실패 위험이 있습니다. [근거: rag/tests/test_evaluator.py:62, rag/agents/evaluator.py:89]
- 기준 일관성: 루브릭이 고정되지 않으면 배치 간 비교가 어려워집니다. [근거: rag/utils/prompts.py:360]

### 현재 완화(코드/테스트 기반)
- temperature를 0.0으로 고정해 평가 변동성을 낮춥니다. [근거: rag/agents/evaluator.py:55]
- 5축 고정 루브릭(각 20점, 총 100점)으로 평가 축을 표준화합니다. [근거: rag/utils/prompts.py:360]
- JSON 강제 + 필수 필드 검증 + 파싱 실패 기본값으로 파이프라인 중단을 방지합니다. [근거: rag/utils/prompts.py:395, rag/agents/evaluator.py:84, rag/agents/evaluator.py:101]
- 통과 임계값을 70으로 고정하여 운영 판정 기준을 일관화합니다. [근거: rag/utils/config/settings.py:226, rag/tests/test_evaluator.py:125]

### 추가 운영 규칙(문서 정책)
- 동일 샘플 반복 평가를 수행하고 점수 편차를 기록합니다.
- `EVALUATOR_PROMPT` 버전을 고정하고 변경 시 변경이력(버전/일자/사유)을 함께 기록합니다. [근거: rag/utils/prompts.py:357]

# 7. 종합 결론

운영 관점의 판정/재시도는 LLM 평가를 사용하고, RAGAS는 선택적 정량 관측에 사용한다는 설계를 테스트와 설정 근거로 문서화했습니다. [근거: rag/agents/router.py:363, rag/agents/router.py:388, rag/utils/config/settings.py:75, rag/utils/config/settings.py:78]
또한 `test_evaluator.py`와 `EVALUATOR_PROMPT`를 연결해 “왜 RAGAS만이 아니라 LLM 평가를 운영 판정에 적용했는지”를 선택 기준-우리 선택-프롬프트 근거 순서로 명확히 제시했습니다. [근거: rag/tests/test_evaluator.py:80, rag/utils/prompts.py:360]
